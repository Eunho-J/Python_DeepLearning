{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26bc02e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 다중 클래스 구조\n",
    "# = 확률적 경사 하강법(Stochastic Gradient Descent) 또는 미니 배치 학습법(mini-batch learning)\n",
    "\n",
    "#MNIST\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a2d9ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "addbff68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "#dataset 형태\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85cd510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = x_train[0]\n",
    "print(img.shape)\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd894976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리 (이미지 2차 배열을 1차 배열로 flatten)\n",
    "def flatten_for_mnist(x):\n",
    "    temp = np.zeros((x.shape[0], x[0].size))\n",
    "    \n",
    "    for idx, data in enumerate(x):\n",
    "        temp[idx, :] = data.flatten()\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2593b90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = flatten_for_mnist(x_train)\n",
    "x_test = flatten_for_mnist(x_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "y_train_ohe = tf.one_hot(y_train, depth=10).numpy()\n",
    "y_test_ohe = tf.one_hot(y_test, depth=10).numpy()\n",
    "\n",
    "print(y_train_ohe.shape)\n",
    "print(y_test_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91fbccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0].max(), x_train[0].min())\n",
    "print(y_train_ohe[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "318eb39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#하이퍼 파라미터 Hyper Parameter\n",
    "epochs = 5\n",
    "lr = 0.3\n",
    "batch_size = 100\n",
    "train_size = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "427d5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#유틸 함수 Util Functions\n",
    "def sigmoid(x):\n",
    "    return 1/ (1 + np.exp(-x))\n",
    "\n",
    "def mean_squared_error(pred_y, true_y):\n",
    "    return np.mean(np.sum(np.square((true_y - pred_y))))\n",
    "\n",
    "def cross_entropy_error(pred_y, true_y):\n",
    "    if true_y.ndim == 1:\n",
    "        true_y = true_y.reshape(1, -1)\n",
    "        pred_y = pred_y.reshape(1, -1)\n",
    "        \n",
    "    delta = 1e-7\n",
    "    return -np.sum(true_y * np.log(pred_y + delta))\n",
    "\n",
    "def cross_entropy_error_for_batch(pred_y, true_y):\n",
    "    if true_y.ndim == 1:\n",
    "        true_y = true_y.reshape(1, -1)\n",
    "        pred_y = pred_y.reshape(1, -1)\n",
    "        \n",
    "    delta = 1e-7\n",
    "    batch_size = pred_y.shape[0]\n",
    "    return -np.sum(true_y * np.log(pred_y + delta)) / batch_size\n",
    "\n",
    "def cross_entropy_error_for_bin(pred_y, true_y):\n",
    "    return 0.5 * np.sum((-true_y * np.log(pred_y) - (1 - true_y) * np.log(1 - pred_y)))\n",
    "\n",
    "def softmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    return exp_a / sum_exp_a\n",
    "\n",
    "def differential_1d(f, x):\n",
    "    eps = 1e-5\n",
    "    diff_value = np.zeros_like(x)\n",
    "    \n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        temp_val = x[i]\n",
    "        \n",
    "        x[i] = temp_val + eps\n",
    "        f_h1 = f(x)\n",
    "        \n",
    "        x[i] = temp_val - eps\n",
    "        f_h2 = f(x)\n",
    "        \n",
    "        diff_value[i] = (f_h1 - f_h2) / (2 * eps)\n",
    "        x[i] = temp_val\n",
    "        \n",
    "    return diff_value\n",
    "\n",
    "def differential_2d(f, X):\n",
    "    if X.ndim == 1:\n",
    "         return differential_1d(f, X)\n",
    "    else:\n",
    "        grad = np.zeros_like(X)\n",
    "        \n",
    "        for idx, x in enumerate(X):\n",
    "            grad[idx] = differential_1d(f, x)\n",
    "        \n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2446584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2층 신경망\n",
    "class MyModel(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        def weight_init(input_nodes, hidden_nodes, output_units):\n",
    "            np.random.seed(777)\n",
    "            params = {}\n",
    "            params['w_1'] = 0.01 * np.random.randn(input_nodes, hidden_nodes)\n",
    "            params['b_1'] = np.zeros(hidden_nodes)\n",
    "            params['w_2'] = 0.01 * np.random.randn(hidden_nodes, output_units)\n",
    "            params['b_2'] = np.zeros(output_units)\n",
    "            return params\n",
    "        \n",
    "        self.params = weight_init(784, 64, 10)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        W_1, W_2 = self.params['w_1'], self.params['w_2']\n",
    "        B_1, B_2 = self.params['b_1'], self.params['b_2']\n",
    "        \n",
    "        A1 = np.dot(x, W_1) + B_1\n",
    "        Z1 = sigmoid(A1)\n",
    "        A2 = np.dot(Z1, W_2) + B_2\n",
    "        pred_y = softmax(A2)\n",
    "        \n",
    "        return pred_y\n",
    "    \n",
    "    def loss(self, x, true_y):\n",
    "        pred_y = self.predict(x)\n",
    "        return cross_entropy_error_for_bin(pred_y, true_y)\n",
    "    \n",
    "    def accuracy(self, x, true_y):\n",
    "        pred_y = self.predict(x)\n",
    "        y_argmax = np.argmax(pred_y, axis=1)\n",
    "        t_argmax = np.argmax(true_y, axis=1)\n",
    "        accuracy = np.sum(y_argmax == t_argmax) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    def get_gradient(self, x, t):\n",
    "        def loss_grad(grad):\n",
    "            return self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['w_1'] = differential_2d(loss_grad, self.params['w_1'])\n",
    "        grads['b_1'] = differential_2d(loss_grad, self.params['b_1'])\n",
    "        grads['w_2'] = differential_2d(loss_grad, self.params['w_2'])\n",
    "        grads['b_2'] = differential_2d(loss_grad, self.params['b_2'])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d4c6c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc01098d26c4a57962af9ab268e9693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Cost: 913.4871128983332, Train Accuracy: 0.10441666666666667, Test Accuracy: 0.1028\n",
      "Epoch: 2, Cost: 410.57309964955533, Train Accuracy: 0.09751666666666667, Test Accuracy: 0.0974\n",
      "Epoch: 3, Cost: 452.0649921784976, Train Accuracy: 0.09871666666666666, Test Accuracy: 0.098\n",
      "Epoch: 4, Cost: 376.3738433788608, Train Accuracy: 0.10218333333333333, Test Accuracy: 0.101\n",
      "Epoch: 5, Cost: 381.6949051777194, Train Accuracy: 0.0993, Test Accuracy: 0.1032\n",
      "총 학습 소요시간: 119.923s\n"
     ]
    }
   ],
   "source": [
    "#모델 생성 및 학습\n",
    "model = MyModel()\n",
    "\n",
    "train_loss_list = list()\n",
    "train_acc_list = list()\n",
    "test_acc_list = list()\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "start_time = time.time()\n",
    "for i in tqdm(range(epochs)):\n",
    "    \n",
    "    batch_idx = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_idx]\n",
    "    y_batch = y_train_ohe[batch_idx]\n",
    "    \n",
    "    grads = model.get_gradient(x_batch, y_batch)\n",
    "    \n",
    "    for key in grads.keys():\n",
    "        model.params[key] -= lr * grads[key]\n",
    "        \n",
    "    loss = model.loss(x_batch, y_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    train_accuracy = model.accuracy(x_train, y_train_ohe)\n",
    "    test_accuracy = model.accuracy(x_test, y_test_ohe)\n",
    "    train_acc_list.append(train_accuracy)\n",
    "    test_acc_list.append(test_accuracy)\n",
    "    \n",
    "    print(\"Epoch: {}, Cost: {}, Train Accuracy: {}, Test Accuracy: {}\"\n",
    "         .format(i+1, loss, train_accuracy, test_accuracy))\n",
    "    \n",
    "end_time = time.time()\n",
    "print(\"총 학습 소요시간: {:.3f}s\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab3a4230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.25927895e-02, 1.05181100e-01, 1.89510909e-01, 4.47110538e-02,\n",
       "       1.03539915e-01, 1.04549135e-01, 1.31130957e-01, 1.10196788e-04,\n",
       "       1.40088465e-01, 1.18585478e-01])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51b5b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
