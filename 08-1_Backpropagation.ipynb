{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8465e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "xs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9b4279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mul():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        result = x * y\n",
    "        return result\n",
    "    \n",
    "    def backward(self, dresult):\n",
    "        #f = xy 에서 dx = y, dy = x\n",
    "        dx = dresult * self.y\n",
    "        dy = dresult * self.x\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee482dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        result = x + y\n",
    "        return result\n",
    "    \n",
    "    def backward(self, dresult):\n",
    "        #f = x + y 에서 dx = 1, dy = 1\n",
    "        dx = dresult\n",
    "        dy = dresult\n",
    "        return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39c70c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = -1, 3, 4\n",
    "x = Add()\n",
    "y = Add()\n",
    "f = Mul()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5961d418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "7\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "x_result = x.forward(a, b)\n",
    "y_result = y.forward(b, c)\n",
    "\n",
    "print(x_result)\n",
    "print(y_result)\n",
    "print(f.forward(x_result, y_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "198c6afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 2\n",
      "7\n",
      "9\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "dresult = 1\n",
    "dx_mul, dy_mul = f.backward(dresult)\n",
    "\n",
    "da_add, db_add_x = x.backward(dx_mul)\n",
    "db_add_y, dc_add = y.backward(dy_mul)\n",
    "\n",
    "print(dx_mul, dy_mul)\n",
    "print(da_add)\n",
    "print(db_add_x + db_add_y)\n",
    "print(dc_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "090bad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#활성화 함수에서의 Backpropagation\n",
    "class Sigmoid():\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xs.append(x[0])\n",
    "        self.out = 1 / (1 + np.exp(-x))\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        #f = 1 / (1 + e^-x) 일 때 df = f(1-f)\n",
    "        dx = dout * (1.0 - self.out) * self.out\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6b50634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReLU\n",
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.mask = (x < 0)\n",
    "        self.out = x.copy()\n",
    "        self.out[x<0] = 0\n",
    "        return self.out\n",
    "            \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4d793b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 행렬 연산에서의 역전파"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cb59404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,) (2, 3) (3,)\n"
     ]
    }
   ],
   "source": [
    "# 순전파\n",
    "X = np.random.rand(2)\n",
    "W = np.random.rand(2, 3)\n",
    "B = np.random.rand(3)\n",
    "\n",
    "print(X.shape, W.shape, B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b321985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "Y = np.dot(X, W) + B\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efc34334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL_dY\n",
      "[-1.08127732  0.53164171  0.84058935]\n",
      "dL_dX\n",
      "[0.29329911 0.71755538]\n",
      "dL_dW\n",
      "[[-0.95625992  0.47017324  0.74340032]\n",
      " [-0.81852747  0.40245304  0.63632655]]\n",
      "dL_dB\n",
      "[-1.08127732  0.53164171  0.84058935]\n"
     ]
    }
   ],
   "source": [
    "#역전파\n",
    "dL_dY = np.random.randn(3)\n",
    "dL_dX = np.dot(dL_dY, W.T)\n",
    "dL_dW = np.dot(X.reshape(-1, 1), dL_dY.reshape(1, -1))\n",
    "dL_dB = dL_dY\n",
    "\n",
    "print(\"dL_dY\\n{}\".format(dL_dY))\n",
    "print(\"dL_dX\\n{}\".format(dL_dX))\n",
    "print(\"dL_dW\\n{}\".format(dL_dW))\n",
    "print(\"dL_dB\\n{}\".format(dL_dB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4731547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(3, 2)\n",
    "        self.b = np.random.randn(2)\n",
    "        self.x = None\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b3be6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(111)\n",
    "\n",
    "layer = Layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5556510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23868214 0.33765619 0.99071246]\n",
      " [0.23772645 0.08119266 0.66960024]]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(2, 3)\n",
    "Y = layer.forward(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b64a345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.59898814  0.83225859 -0.61525238]\n",
      " [-0.48312871  0.65565961 -0.42154775]]\n"
     ]
    }
   ],
   "source": [
    "dout = np.random.rand(2, 2)\n",
    "dout_dx = layer.backward(dout)\n",
    "\n",
    "print(dout_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0ba87b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##MNIST 분류\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e5ff034",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddd393b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리\n",
    "X_train, X_test = X_train.reshape(-1, 28 * 28).astype(np.float32), X_test.reshape(-1, 28 * 28).astype(np.float32)\n",
    "\n",
    "X_train /= .255\n",
    "X_test /= .255\n",
    "\n",
    "y_train = np.eye(num_classes)[y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e575499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n",
      "(10000, 784)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4218dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper Parameters\n",
    "epochs = 1000\n",
    "learning_rate = 1e-3\n",
    "batch_size = 100\n",
    "train_size = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1484e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Util Functions\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "\n",
    "def mean_squared_error(pred_y, true_y):\n",
    "    return 0.5 * np.sum((pred_y - true_y) ** 2)\n",
    "\n",
    "def cross_entropy_error(pred_y, true_y):\n",
    "    if pred_y.ndim == 1:\n",
    "        true_y = true_y.reshape(1, true_y.size)\n",
    "        pred_y = pred_y.reshape(1, pred_y.size)\n",
    "        \n",
    "    if pred_y.size == true_y.size:\n",
    "        true_y = true_y.argmax(axis=1)\n",
    "        \n",
    "    batch_size = pred_y.shape[0]\n",
    "    return -np.sum(np.log(pred_y[np.arange(batch_size), true_y] + 1e-7)) / batch_size\n",
    "\n",
    "def softmax_loss(X, true_y):\n",
    "    pred_y = softmax(X)\n",
    "    return cross_entropy_error(pred_y, true_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91322357",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.origin_x_shape = None\n",
    "        \n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.origin_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        dx = dx.reshape(*self.origin_x_shape)\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40a65edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax():\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        self.t = None\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        \n",
    "        if self.t.size == self.y.size:\n",
    "            dx = (self.y - self.t) / batch_size\n",
    "        else:\n",
    "            dx = self.y.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1\n",
    "            dx = dx / batch_size\n",
    "            \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76d869d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel():\n",
    "    def __init__(self, input_size, hidden_size_list, output_size, activation='relu'):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self. hidden_size_list = hidden_size_list\n",
    "        self.hidden_layer_num = len(hidden_size_list)\n",
    "        self.params = {}\n",
    "        \n",
    "        self.__init_weights(activation)\n",
    "        \n",
    "        activation_layer = {'sigmoid': Sigmoid, 'relu': ReLU}\n",
    "        self.layers = OrderedDict()\n",
    "        \n",
    "        for idx in range(1, self.hidden_layer_num + 1):\n",
    "            self.layers['Layer' + str(idx)] = Layer(self.params['W' + str(idx)], self.params['b' + str(idx)])\n",
    "            self.layers['Activation_function' + str(idx)] = activation_layer[activation]()\n",
    "            \n",
    "        idx = self.hidden_layer_num + 1\n",
    "        self.layers['Layer' + str(idx)] = Layer(self.params['W' + str(idx)], self.params['b' + str(idx)])\n",
    "        \n",
    "        self.last_layer = Softmax()\n",
    "        \n",
    "    def __init_weights(self, activation):\n",
    "        weight_std = None\n",
    "        all_size_list = [self.input_size] + self.hidden_size_list + [self.output_size]\n",
    "        \n",
    "        for idx in range(1, len(all_size_list)):\n",
    "            if activation.lower() == 'relu':\n",
    "                weight_std = np.sqrt(2.0 / self.input_size)\n",
    "            elif activation.lower() == 'sigmoid':\n",
    "                weight_std = 2.0 * np.sqrt(2.0 / (all_size_list[idx - 1] + all_size_list[idx]))\n",
    "            \n",
    "            self.params['W' + str(idx)] = weight_std * np.random.randn(all_size_list[idx - 1], all_size_list[idx])\n",
    "            self.params['b' + str(idx)] = np.random.randn(all_size_list[idx])\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x , true_y):\n",
    "        pred_y = self.predict(x)\n",
    "        return self.last_layer.forward(pred_y, true_y)\n",
    "    \n",
    "    def accuracy(self, x, true_y):\n",
    "        pred_y = self.predict(x)\n",
    "        pred_y = np.argmax(pred_y, axis=1)\n",
    "        \n",
    "        if true_y.ndim != 1:\n",
    "            true_y = np.argmax(true_y, axis=1)\n",
    "            \n",
    "        accuracy = np.sum(pred_y == true_y) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        self.loss(x, t)\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "            \n",
    "        grads = {}\n",
    "        for idx in range(1, self.hidden_layer_num + 2):\n",
    "            grads['W' + str(idx)] = self.layers['Layer' + str(idx)].dW\n",
    "            grads['b' + str(idx)] = self.layers['Layer' + str(idx)].db\n",
    "            \n",
    "        return grads\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1dbd1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 생성 및 학습\n",
    "model = MyModel(28 * 28, [100, 64, 32], 10, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2b152f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ef20ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Acc: 0.1621, Test Acc: 0.1634\n",
      "Epoch: 51, Train Acc: 0.5871, Test Acc: 0.5916\n",
      "Epoch: 101, Train Acc: 0.6942, Test Acc: 0.6945\n",
      "Epoch: 151, Train Acc: 0.7302, Test Acc: 0.7286\n",
      "Epoch: 201, Train Acc: 0.7646, Test Acc: 0.7625\n",
      "Epoch: 251, Train Acc: 0.7814, Test Acc: 0.7819\n",
      "Epoch: 301, Train Acc: 0.8047, Test Acc: 0.8046\n",
      "Epoch: 351, Train Acc: 0.8123, Test Acc: 0.8102\n",
      "Epoch: 401, Train Acc: 0.8188, Test Acc: 0.8168\n",
      "Epoch: 451, Train Acc: 0.8321, Test Acc: 0.8305\n",
      "Epoch: 501, Train Acc: 0.8391, Test Acc: 0.8376\n",
      "Epoch: 551, Train Acc: 0.8465, Test Acc: 0.8418\n",
      "Epoch: 601, Train Acc: 0.8465, Test Acc: 0.8413\n",
      "Epoch: 651, Train Acc: 0.8572, Test Acc: 0.8539\n",
      "Epoch: 701, Train Acc: 0.8594, Test Acc: 0.8544\n",
      "Epoch: 751, Train Acc: 0.8659, Test Acc: 0.8599\n",
      "Epoch: 801, Train Acc: 0.8727, Test Acc: 0.8673\n",
      "Epoch: 851, Train Acc: 0.8720, Test Acc: 0.8677\n",
      "Epoch: 901, Train Acc: 0.8747, Test Acc: 0.8691\n",
      "Epoch: 951, Train Acc: 0.8786, Test Acc: 0.8748\n",
      "Epoch: 1001, Train Acc: 0.8842, Test Acc: 0.8796\n",
      "Epoch: 1051, Train Acc: 0.8806, Test Acc: 0.8738\n",
      "Epoch: 1101, Train Acc: 0.8860, Test Acc: 0.8786\n",
      "Epoch: 1151, Train Acc: 0.8912, Test Acc: 0.8875\n",
      "Epoch: 1201, Train Acc: 0.8852, Test Acc: 0.8803\n",
      "Epoch: 1251, Train Acc: 0.8925, Test Acc: 0.8861\n",
      "Epoch: 1301, Train Acc: 0.8943, Test Acc: 0.8864\n",
      "Epoch: 1351, Train Acc: 0.8968, Test Acc: 0.8928\n",
      "Epoch: 1401, Train Acc: 0.8966, Test Acc: 0.8919\n",
      "Epoch: 1451, Train Acc: 0.9001, Test Acc: 0.8925\n",
      "Epoch: 1501, Train Acc: 0.9040, Test Acc: 0.8981\n",
      "Epoch: 1551, Train Acc: 0.9042, Test Acc: 0.8982\n",
      "Epoch: 1601, Train Acc: 0.9059, Test Acc: 0.9009\n",
      "Epoch: 1651, Train Acc: 0.9073, Test Acc: 0.9019\n",
      "Epoch: 1701, Train Acc: 0.9042, Test Acc: 0.8999\n",
      "Epoch: 1751, Train Acc: 0.9103, Test Acc: 0.9048\n",
      "Epoch: 1801, Train Acc: 0.9076, Test Acc: 0.9005\n",
      "Epoch: 1851, Train Acc: 0.9061, Test Acc: 0.9021\n",
      "Epoch: 1901, Train Acc: 0.9126, Test Acc: 0.9068\n",
      "Epoch: 1951, Train Acc: 0.9126, Test Acc: 0.9074\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = X_train[batch_mask]\n",
    "    y_batch = y_train[batch_mask]\n",
    "    \n",
    "    grad = model.gradient(x_batch, y_batch)\n",
    "    \n",
    "    for key in model.params.keys():\n",
    "        model.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    loss = model.loss(x_batch, y_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        train_acc = model.accuracy(X_train, y_train)\n",
    "        test_acc = model.accuracy(X_test, y_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"Epoch: {}, Train Acc: {:.4f}, Test Acc: {:.4f}\".format(epoch + 1, train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d9452d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(epochs//50), train_acc_list, 'r--', label='train_acc')\n",
    "plt.plot(np.arange(epochs//50), test_acc_list, 'b--', label='test_acc')\n",
    "\n",
    "plt.title('Result')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=5)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cb9d9ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(epochs), train_loss_list, 'green', label='train_loss')\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=5)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c5daf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_5760/3331577091.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  self.out = 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Acc: 0.0974, Test Acc: 0.0982\n",
      "Epoch: 51, Train Acc: 0.0975, Test Acc: 0.0989\n",
      "Epoch: 101, Train Acc: 0.1119, Test Acc: 0.1109\n",
      "Epoch: 151, Train Acc: 0.1789, Test Acc: 0.1792\n",
      "Epoch: 201, Train Acc: 0.2615, Test Acc: 0.2591\n",
      "Epoch: 251, Train Acc: 0.2849, Test Acc: 0.2870\n",
      "Epoch: 301, Train Acc: 0.3025, Test Acc: 0.3072\n",
      "Epoch: 351, Train Acc: 0.3067, Test Acc: 0.3094\n",
      "Epoch: 401, Train Acc: 0.3938, Test Acc: 0.4042\n",
      "Epoch: 451, Train Acc: 0.3993, Test Acc: 0.4075\n",
      "Epoch: 501, Train Acc: 0.3939, Test Acc: 0.4073\n",
      "Epoch: 551, Train Acc: 0.4217, Test Acc: 0.4285\n",
      "Epoch: 601, Train Acc: 0.4337, Test Acc: 0.4444\n",
      "Epoch: 651, Train Acc: 0.4220, Test Acc: 0.4277\n",
      "Epoch: 701, Train Acc: 0.4356, Test Acc: 0.4464\n",
      "Epoch: 751, Train Acc: 0.3990, Test Acc: 0.4137\n",
      "Epoch: 801, Train Acc: 0.4509, Test Acc: 0.4673\n",
      "Epoch: 851, Train Acc: 0.4409, Test Acc: 0.4585\n",
      "Epoch: 901, Train Acc: 0.4374, Test Acc: 0.4544\n",
      "Epoch: 951, Train Acc: 0.5150, Test Acc: 0.5262\n",
      "Epoch: 1001, Train Acc: 0.4936, Test Acc: 0.5026\n",
      "Epoch: 1051, Train Acc: 0.5200, Test Acc: 0.5325\n",
      "Epoch: 1101, Train Acc: 0.5110, Test Acc: 0.5243\n",
      "Epoch: 1151, Train Acc: 0.5549, Test Acc: 0.5675\n",
      "Epoch: 1201, Train Acc: 0.5361, Test Acc: 0.5461\n",
      "Epoch: 1251, Train Acc: 0.5260, Test Acc: 0.5325\n",
      "Epoch: 1301, Train Acc: 0.5576, Test Acc: 0.5681\n",
      "Epoch: 1351, Train Acc: 0.5700, Test Acc: 0.5799\n",
      "Epoch: 1401, Train Acc: 0.5278, Test Acc: 0.5318\n",
      "Epoch: 1451, Train Acc: 0.5840, Test Acc: 0.5902\n",
      "Epoch: 1501, Train Acc: 0.5957, Test Acc: 0.6051\n",
      "Epoch: 1551, Train Acc: 0.5968, Test Acc: 0.6026\n",
      "Epoch: 1601, Train Acc: 0.6055, Test Acc: 0.6139\n",
      "Epoch: 1651, Train Acc: 0.6021, Test Acc: 0.6106\n",
      "Epoch: 1701, Train Acc: 0.6059, Test Acc: 0.6181\n",
      "Epoch: 1751, Train Acc: 0.5588, Test Acc: 0.5631\n",
      "Epoch: 1801, Train Acc: 0.6054, Test Acc: 0.6103\n",
      "Epoch: 1851, Train Acc: 0.6221, Test Acc: 0.6257\n",
      "Epoch: 1901, Train Acc: 0.6211, Test Acc: 0.6273\n",
      "Epoch: 1951, Train Acc: 0.6324, Test Acc: 0.6419\n",
      "Epoch: 2001, Train Acc: 0.6498, Test Acc: 0.6531\n",
      "Epoch: 2051, Train Acc: 0.6270, Test Acc: 0.6399\n",
      "Epoch: 2101, Train Acc: 0.6200, Test Acc: 0.6283\n",
      "Epoch: 2151, Train Acc: 0.6067, Test Acc: 0.6117\n",
      "Epoch: 2201, Train Acc: 0.6205, Test Acc: 0.6241\n",
      "Epoch: 2251, Train Acc: 0.6208, Test Acc: 0.6227\n",
      "Epoch: 2301, Train Acc: 0.5840, Test Acc: 0.5892\n",
      "Epoch: 2351, Train Acc: 0.6463, Test Acc: 0.6484\n",
      "Epoch: 2401, Train Acc: 0.6568, Test Acc: 0.6617\n",
      "Epoch: 2451, Train Acc: 0.6545, Test Acc: 0.6604\n",
      "Epoch: 2501, Train Acc: 0.6425, Test Acc: 0.6480\n",
      "Epoch: 2551, Train Acc: 0.6569, Test Acc: 0.6613\n",
      "Epoch: 2601, Train Acc: 0.6656, Test Acc: 0.6713\n",
      "Epoch: 2651, Train Acc: 0.6663, Test Acc: 0.6695\n",
      "Epoch: 2701, Train Acc: 0.6758, Test Acc: 0.6819\n",
      "Epoch: 2751, Train Acc: 0.6805, Test Acc: 0.6842\n",
      "Epoch: 2801, Train Acc: 0.6643, Test Acc: 0.6659\n",
      "Epoch: 2851, Train Acc: 0.6780, Test Acc: 0.6810\n",
      "Epoch: 2901, Train Acc: 0.6901, Test Acc: 0.7009\n",
      "Epoch: 2951, Train Acc: 0.6929, Test Acc: 0.6928\n",
      "Epoch: 3001, Train Acc: 0.6707, Test Acc: 0.6737\n",
      "Epoch: 3051, Train Acc: 0.6796, Test Acc: 0.6874\n",
      "Epoch: 3101, Train Acc: 0.6670, Test Acc: 0.6773\n",
      "Epoch: 3151, Train Acc: 0.6802, Test Acc: 0.6874\n",
      "Epoch: 3201, Train Acc: 0.6896, Test Acc: 0.6973\n",
      "Epoch: 3251, Train Acc: 0.7041, Test Acc: 0.7096\n",
      "Epoch: 3301, Train Acc: 0.6776, Test Acc: 0.6826\n",
      "Epoch: 3351, Train Acc: 0.6962, Test Acc: 0.7005\n",
      "Epoch: 3401, Train Acc: 0.6808, Test Acc: 0.6831\n",
      "Epoch: 3451, Train Acc: 0.7089, Test Acc: 0.7130\n",
      "Epoch: 3501, Train Acc: 0.7219, Test Acc: 0.7226\n",
      "Epoch: 3551, Train Acc: 0.7375, Test Acc: 0.7409\n",
      "Epoch: 3601, Train Acc: 0.7375, Test Acc: 0.7400\n",
      "Epoch: 3651, Train Acc: 0.7322, Test Acc: 0.7436\n",
      "Epoch: 3701, Train Acc: 0.7180, Test Acc: 0.7257\n",
      "Epoch: 3751, Train Acc: 0.7265, Test Acc: 0.7330\n",
      "Epoch: 3801, Train Acc: 0.7154, Test Acc: 0.7166\n",
      "Epoch: 3851, Train Acc: 0.7275, Test Acc: 0.7314\n",
      "Epoch: 3901, Train Acc: 0.7231, Test Acc: 0.7309\n",
      "Epoch: 3951, Train Acc: 0.7309, Test Acc: 0.7350\n",
      "Epoch: 4001, Train Acc: 0.7289, Test Acc: 0.7302\n",
      "Epoch: 4051, Train Acc: 0.7352, Test Acc: 0.7421\n",
      "Epoch: 4101, Train Acc: 0.7444, Test Acc: 0.7472\n",
      "Epoch: 4151, Train Acc: 0.7374, Test Acc: 0.7443\n",
      "Epoch: 4201, Train Acc: 0.7494, Test Acc: 0.7560\n",
      "Epoch: 4251, Train Acc: 0.7290, Test Acc: 0.7322\n",
      "Epoch: 4301, Train Acc: 0.7429, Test Acc: 0.7505\n",
      "Epoch: 4351, Train Acc: 0.7325, Test Acc: 0.7441\n",
      "Epoch: 4401, Train Acc: 0.7383, Test Acc: 0.7445\n",
      "Epoch: 4451, Train Acc: 0.7332, Test Acc: 0.7346\n",
      "Epoch: 4501, Train Acc: 0.7257, Test Acc: 0.7311\n",
      "Epoch: 4551, Train Acc: 0.7394, Test Acc: 0.7477\n",
      "Epoch: 4601, Train Acc: 0.7320, Test Acc: 0.7430\n",
      "Epoch: 4651, Train Acc: 0.7405, Test Acc: 0.7458\n",
      "Epoch: 4701, Train Acc: 0.7474, Test Acc: 0.7503\n",
      "Epoch: 4751, Train Acc: 0.7470, Test Acc: 0.7500\n",
      "Epoch: 4801, Train Acc: 0.7431, Test Acc: 0.7443\n",
      "Epoch: 4851, Train Acc: 0.7520, Test Acc: 0.7540\n",
      "Epoch: 4901, Train Acc: 0.7497, Test Acc: 0.7575\n",
      "Epoch: 4951, Train Acc: 0.7424, Test Acc: 0.7510\n",
      "Epoch: 5001, Train Acc: 0.7381, Test Acc: 0.7452\n",
      "Epoch: 5051, Train Acc: 0.7410, Test Acc: 0.7462\n",
      "Epoch: 5101, Train Acc: 0.7500, Test Acc: 0.7469\n",
      "Epoch: 5151, Train Acc: 0.7447, Test Acc: 0.7458\n",
      "Epoch: 5201, Train Acc: 0.7412, Test Acc: 0.7432\n",
      "Epoch: 5251, Train Acc: 0.7485, Test Acc: 0.7454\n",
      "Epoch: 5301, Train Acc: 0.7534, Test Acc: 0.7527\n",
      "Epoch: 5351, Train Acc: 0.7517, Test Acc: 0.7520\n",
      "Epoch: 5401, Train Acc: 0.7552, Test Acc: 0.7570\n",
      "Epoch: 5451, Train Acc: 0.7629, Test Acc: 0.7698\n",
      "Epoch: 5501, Train Acc: 0.7441, Test Acc: 0.7451\n",
      "Epoch: 5551, Train Acc: 0.7532, Test Acc: 0.7570\n",
      "Epoch: 5601, Train Acc: 0.7498, Test Acc: 0.7548\n",
      "Epoch: 5651, Train Acc: 0.7495, Test Acc: 0.7525\n",
      "Epoch: 5701, Train Acc: 0.7411, Test Acc: 0.7453\n",
      "Epoch: 5751, Train Acc: 0.7283, Test Acc: 0.7371\n",
      "Epoch: 5801, Train Acc: 0.7478, Test Acc: 0.7547\n",
      "Epoch: 5851, Train Acc: 0.7407, Test Acc: 0.7532\n",
      "Epoch: 5901, Train Acc: 0.7465, Test Acc: 0.7532\n",
      "Epoch: 5951, Train Acc: 0.7503, Test Acc: 0.7547\n",
      "Epoch: 6001, Train Acc: 0.7467, Test Acc: 0.7483\n",
      "Epoch: 6051, Train Acc: 0.7468, Test Acc: 0.7490\n",
      "Epoch: 6101, Train Acc: 0.7443, Test Acc: 0.7503\n",
      "Epoch: 6151, Train Acc: 0.7558, Test Acc: 0.7619\n",
      "Epoch: 6201, Train Acc: 0.7463, Test Acc: 0.7563\n",
      "Epoch: 6251, Train Acc: 0.7602, Test Acc: 0.7727\n",
      "Epoch: 6301, Train Acc: 0.7618, Test Acc: 0.7698\n",
      "Epoch: 6351, Train Acc: 0.7494, Test Acc: 0.7570\n",
      "Epoch: 6401, Train Acc: 0.7291, Test Acc: 0.7406\n",
      "Epoch: 6451, Train Acc: 0.7436, Test Acc: 0.7526\n",
      "Epoch: 6501, Train Acc: 0.7479, Test Acc: 0.7527\n",
      "Epoch: 6551, Train Acc: 0.7502, Test Acc: 0.7599\n",
      "Epoch: 6601, Train Acc: 0.7528, Test Acc: 0.7617\n",
      "Epoch: 6651, Train Acc: 0.7447, Test Acc: 0.7544\n",
      "Epoch: 6701, Train Acc: 0.7237, Test Acc: 0.7380\n",
      "Epoch: 6751, Train Acc: 0.7503, Test Acc: 0.7652\n",
      "Epoch: 6801, Train Acc: 0.7548, Test Acc: 0.7617\n",
      "Epoch: 6851, Train Acc: 0.7498, Test Acc: 0.7560\n",
      "Epoch: 6901, Train Acc: 0.7459, Test Acc: 0.7485\n",
      "Epoch: 6951, Train Acc: 0.7569, Test Acc: 0.7638\n",
      "Epoch: 7001, Train Acc: 0.7648, Test Acc: 0.7646\n",
      "Epoch: 7051, Train Acc: 0.7668, Test Acc: 0.7721\n",
      "Epoch: 7101, Train Acc: 0.7569, Test Acc: 0.7605\n",
      "Epoch: 7151, Train Acc: 0.7602, Test Acc: 0.7632\n",
      "Epoch: 7201, Train Acc: 0.7433, Test Acc: 0.7466\n",
      "Epoch: 7251, Train Acc: 0.7595, Test Acc: 0.7688\n",
      "Epoch: 7301, Train Acc: 0.7587, Test Acc: 0.7659\n",
      "Epoch: 7351, Train Acc: 0.7609, Test Acc: 0.7689\n",
      "Epoch: 7401, Train Acc: 0.7576, Test Acc: 0.7625\n",
      "Epoch: 7451, Train Acc: 0.7593, Test Acc: 0.7683\n",
      "Epoch: 7501, Train Acc: 0.7538, Test Acc: 0.7640\n",
      "Epoch: 7551, Train Acc: 0.7601, Test Acc: 0.7728\n",
      "Epoch: 7601, Train Acc: 0.7662, Test Acc: 0.7752\n",
      "Epoch: 7651, Train Acc: 0.7663, Test Acc: 0.7753\n",
      "Epoch: 7701, Train Acc: 0.7534, Test Acc: 0.7591\n",
      "Epoch: 7751, Train Acc: 0.7674, Test Acc: 0.7748\n",
      "Epoch: 7801, Train Acc: 0.7652, Test Acc: 0.7729\n",
      "Epoch: 7851, Train Acc: 0.7366, Test Acc: 0.7422\n",
      "Epoch: 7901, Train Acc: 0.7446, Test Acc: 0.7482\n",
      "Epoch: 7951, Train Acc: 0.7406, Test Acc: 0.7496\n",
      "Epoch: 8001, Train Acc: 0.7429, Test Acc: 0.7546\n",
      "Epoch: 8051, Train Acc: 0.7499, Test Acc: 0.7594\n",
      "Epoch: 8101, Train Acc: 0.7510, Test Acc: 0.7601\n",
      "Epoch: 8151, Train Acc: 0.7406, Test Acc: 0.7490\n",
      "Epoch: 8201, Train Acc: 0.7414, Test Acc: 0.7441\n",
      "Epoch: 8251, Train Acc: 0.7538, Test Acc: 0.7597\n",
      "Epoch: 8301, Train Acc: 0.7548, Test Acc: 0.7572\n",
      "Epoch: 8351, Train Acc: 0.7696, Test Acc: 0.7728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8401, Train Acc: 0.7641, Test Acc: 0.7621\n",
      "Epoch: 8451, Train Acc: 0.7672, Test Acc: 0.7720\n",
      "Epoch: 8501, Train Acc: 0.7503, Test Acc: 0.7591\n",
      "Epoch: 8551, Train Acc: 0.7529, Test Acc: 0.7607\n",
      "Epoch: 8601, Train Acc: 0.7537, Test Acc: 0.7578\n",
      "Epoch: 8651, Train Acc: 0.7643, Test Acc: 0.7697\n",
      "Epoch: 8701, Train Acc: 0.7603, Test Acc: 0.7692\n",
      "Epoch: 8751, Train Acc: 0.7655, Test Acc: 0.7670\n",
      "Epoch: 8801, Train Acc: 0.7505, Test Acc: 0.7544\n",
      "Epoch: 8851, Train Acc: 0.7510, Test Acc: 0.7549\n",
      "Epoch: 8901, Train Acc: 0.7611, Test Acc: 0.7649\n",
      "Epoch: 8951, Train Acc: 0.7514, Test Acc: 0.7543\n",
      "Epoch: 9001, Train Acc: 0.7588, Test Acc: 0.7625\n",
      "Epoch: 9051, Train Acc: 0.7557, Test Acc: 0.7612\n",
      "Epoch: 9101, Train Acc: 0.7595, Test Acc: 0.7684\n",
      "Epoch: 9151, Train Acc: 0.7561, Test Acc: 0.7608\n",
      "Epoch: 9201, Train Acc: 0.7637, Test Acc: 0.7688\n",
      "Epoch: 9251, Train Acc: 0.7687, Test Acc: 0.7730\n",
      "Epoch: 9301, Train Acc: 0.7664, Test Acc: 0.7771\n",
      "Epoch: 9351, Train Acc: 0.7656, Test Acc: 0.7685\n",
      "Epoch: 9401, Train Acc: 0.7687, Test Acc: 0.7765\n",
      "Epoch: 9451, Train Acc: 0.7656, Test Acc: 0.7757\n",
      "Epoch: 9501, Train Acc: 0.7716, Test Acc: 0.7833\n",
      "Epoch: 9551, Train Acc: 0.7776, Test Acc: 0.7888\n",
      "Epoch: 9601, Train Acc: 0.7764, Test Acc: 0.7840\n",
      "Epoch: 9651, Train Acc: 0.7832, Test Acc: 0.7940\n",
      "Epoch: 9701, Train Acc: 0.7665, Test Acc: 0.7738\n",
      "Epoch: 9751, Train Acc: 0.7702, Test Acc: 0.7797\n",
      "Epoch: 9801, Train Acc: 0.7587, Test Acc: 0.7615\n",
      "Epoch: 9851, Train Acc: 0.7707, Test Acc: 0.7782\n",
      "Epoch: 9901, Train Acc: 0.7767, Test Acc: 0.7822\n",
      "Epoch: 9951, Train Acc: 0.7658, Test Acc: 0.7662\n",
      "Epoch: 10001, Train Acc: 0.7643, Test Acc: 0.7697\n",
      "Epoch: 10051, Train Acc: 0.7826, Test Acc: 0.7923\n",
      "Epoch: 10101, Train Acc: 0.7838, Test Acc: 0.7919\n",
      "Epoch: 10151, Train Acc: 0.7883, Test Acc: 0.7954\n",
      "Epoch: 10201, Train Acc: 0.7585, Test Acc: 0.7658\n",
      "Epoch: 10251, Train Acc: 0.7557, Test Acc: 0.7566\n",
      "Epoch: 10301, Train Acc: 0.7613, Test Acc: 0.7631\n",
      "Epoch: 10351, Train Acc: 0.7512, Test Acc: 0.7538\n",
      "Epoch: 10401, Train Acc: 0.7493, Test Acc: 0.7574\n",
      "Epoch: 10451, Train Acc: 0.7510, Test Acc: 0.7568\n",
      "Epoch: 10501, Train Acc: 0.7520, Test Acc: 0.7575\n",
      "Epoch: 10551, Train Acc: 0.7631, Test Acc: 0.7691\n",
      "Epoch: 10601, Train Acc: 0.7660, Test Acc: 0.7773\n",
      "Epoch: 10651, Train Acc: 0.7633, Test Acc: 0.7712\n",
      "Epoch: 10701, Train Acc: 0.7641, Test Acc: 0.7742\n",
      "Epoch: 10751, Train Acc: 0.7563, Test Acc: 0.7652\n",
      "Epoch: 10801, Train Acc: 0.7611, Test Acc: 0.7652\n",
      "Epoch: 10851, Train Acc: 0.7610, Test Acc: 0.7685\n",
      "Epoch: 10901, Train Acc: 0.7599, Test Acc: 0.7629\n",
      "Epoch: 10951, Train Acc: 0.7545, Test Acc: 0.7620\n",
      "Epoch: 11001, Train Acc: 0.7661, Test Acc: 0.7703\n",
      "Epoch: 11051, Train Acc: 0.7626, Test Acc: 0.7701\n",
      "Epoch: 11101, Train Acc: 0.7531, Test Acc: 0.7593\n",
      "Epoch: 11151, Train Acc: 0.7403, Test Acc: 0.7486\n",
      "Epoch: 11201, Train Acc: 0.7418, Test Acc: 0.7490\n",
      "Epoch: 11251, Train Acc: 0.7713, Test Acc: 0.7779\n",
      "Epoch: 11301, Train Acc: 0.7514, Test Acc: 0.7620\n",
      "Epoch: 11351, Train Acc: 0.7499, Test Acc: 0.7558\n",
      "Epoch: 11401, Train Acc: 0.7492, Test Acc: 0.7546\n",
      "Epoch: 11451, Train Acc: 0.7595, Test Acc: 0.7633\n",
      "Epoch: 11501, Train Acc: 0.7585, Test Acc: 0.7616\n",
      "Epoch: 11551, Train Acc: 0.7565, Test Acc: 0.7614\n",
      "Epoch: 11601, Train Acc: 0.7532, Test Acc: 0.7584\n",
      "Epoch: 11651, Train Acc: 0.7596, Test Acc: 0.7632\n",
      "Epoch: 11701, Train Acc: 0.7554, Test Acc: 0.7556\n",
      "Epoch: 11751, Train Acc: 0.7407, Test Acc: 0.7389\n",
      "Epoch: 11801, Train Acc: 0.7471, Test Acc: 0.7496\n",
      "Epoch: 11851, Train Acc: 0.7607, Test Acc: 0.7672\n",
      "Epoch: 11901, Train Acc: 0.7594, Test Acc: 0.7635\n",
      "Epoch: 11951, Train Acc: 0.7592, Test Acc: 0.7674\n",
      "Epoch: 12001, Train Acc: 0.7643, Test Acc: 0.7725\n",
      "Epoch: 12051, Train Acc: 0.7658, Test Acc: 0.7766\n",
      "Epoch: 12101, Train Acc: 0.7556, Test Acc: 0.7606\n",
      "Epoch: 12151, Train Acc: 0.7664, Test Acc: 0.7733\n",
      "Epoch: 12201, Train Acc: 0.7521, Test Acc: 0.7559\n",
      "Epoch: 12251, Train Acc: 0.7470, Test Acc: 0.7535\n",
      "Epoch: 12301, Train Acc: 0.7552, Test Acc: 0.7667\n",
      "Epoch: 12351, Train Acc: 0.7608, Test Acc: 0.7717\n",
      "Epoch: 12401, Train Acc: 0.7634, Test Acc: 0.7748\n",
      "Epoch: 12451, Train Acc: 0.7635, Test Acc: 0.7731\n",
      "Epoch: 12501, Train Acc: 0.7643, Test Acc: 0.7789\n",
      "Epoch: 12551, Train Acc: 0.7638, Test Acc: 0.7773\n",
      "Epoch: 12601, Train Acc: 0.7657, Test Acc: 0.7741\n",
      "Epoch: 12651, Train Acc: 0.7716, Test Acc: 0.7761\n",
      "Epoch: 12701, Train Acc: 0.7765, Test Acc: 0.7856\n",
      "Epoch: 12751, Train Acc: 0.7696, Test Acc: 0.7761\n",
      "Epoch: 12801, Train Acc: 0.7740, Test Acc: 0.7822\n",
      "Epoch: 12851, Train Acc: 0.7718, Test Acc: 0.7828\n",
      "Epoch: 12901, Train Acc: 0.7778, Test Acc: 0.7849\n",
      "Epoch: 12951, Train Acc: 0.7855, Test Acc: 0.7921\n",
      "Epoch: 13001, Train Acc: 0.7914, Test Acc: 0.7972\n",
      "Epoch: 13051, Train Acc: 0.7900, Test Acc: 0.8004\n",
      "Epoch: 13101, Train Acc: 0.7800, Test Acc: 0.7901\n",
      "Epoch: 13151, Train Acc: 0.7843, Test Acc: 0.7896\n",
      "Epoch: 13201, Train Acc: 0.7749, Test Acc: 0.7867\n",
      "Epoch: 13251, Train Acc: 0.7739, Test Acc: 0.7855\n",
      "Epoch: 13301, Train Acc: 0.7631, Test Acc: 0.7703\n",
      "Epoch: 13351, Train Acc: 0.7633, Test Acc: 0.7644\n",
      "Epoch: 13401, Train Acc: 0.7621, Test Acc: 0.7635\n",
      "Epoch: 13451, Train Acc: 0.7635, Test Acc: 0.7671\n",
      "Epoch: 13501, Train Acc: 0.7571, Test Acc: 0.7639\n",
      "Epoch: 13551, Train Acc: 0.7479, Test Acc: 0.7551\n",
      "Epoch: 13601, Train Acc: 0.7518, Test Acc: 0.7560\n",
      "Epoch: 13651, Train Acc: 0.7570, Test Acc: 0.7633\n",
      "Epoch: 13701, Train Acc: 0.7516, Test Acc: 0.7592\n",
      "Epoch: 13751, Train Acc: 0.7633, Test Acc: 0.7698\n",
      "Epoch: 13801, Train Acc: 0.7631, Test Acc: 0.7731\n",
      "Epoch: 13851, Train Acc: 0.7671, Test Acc: 0.7767\n",
      "Epoch: 13901, Train Acc: 0.7479, Test Acc: 0.7572\n",
      "Epoch: 13951, Train Acc: 0.7611, Test Acc: 0.7689\n",
      "Epoch: 14001, Train Acc: 0.7629, Test Acc: 0.7708\n",
      "Epoch: 14051, Train Acc: 0.7539, Test Acc: 0.7565\n",
      "Epoch: 14101, Train Acc: 0.7547, Test Acc: 0.7633\n",
      "Epoch: 14151, Train Acc: 0.7640, Test Acc: 0.7643\n",
      "Epoch: 14201, Train Acc: 0.7584, Test Acc: 0.7624\n",
      "Epoch: 14251, Train Acc: 0.7567, Test Acc: 0.7592\n",
      "Epoch: 14301, Train Acc: 0.7608, Test Acc: 0.7620\n",
      "Epoch: 14351, Train Acc: 0.7137, Test Acc: 0.7126\n",
      "Epoch: 14401, Train Acc: 0.7285, Test Acc: 0.7296\n",
      "Epoch: 14451, Train Acc: 0.7332, Test Acc: 0.7342\n",
      "Epoch: 14501, Train Acc: 0.7302, Test Acc: 0.7285\n",
      "Epoch: 14551, Train Acc: 0.7325, Test Acc: 0.7341\n",
      "Epoch: 14601, Train Acc: 0.7429, Test Acc: 0.7412\n",
      "Epoch: 14651, Train Acc: 0.7400, Test Acc: 0.7352\n",
      "Epoch: 14701, Train Acc: 0.7404, Test Acc: 0.7362\n",
      "Epoch: 14751, Train Acc: 0.7300, Test Acc: 0.7289\n",
      "Epoch: 14801, Train Acc: 0.7304, Test Acc: 0.7244\n",
      "Epoch: 14851, Train Acc: 0.7272, Test Acc: 0.7207\n",
      "Epoch: 14901, Train Acc: 0.7361, Test Acc: 0.7358\n",
      "Epoch: 14951, Train Acc: 0.7322, Test Acc: 0.7323\n",
      "Epoch: 15001, Train Acc: 0.7455, Test Acc: 0.7516\n",
      "Epoch: 15051, Train Acc: 0.7440, Test Acc: 0.7506\n",
      "Epoch: 15101, Train Acc: 0.7483, Test Acc: 0.7561\n",
      "Epoch: 15151, Train Acc: 0.7420, Test Acc: 0.7426\n",
      "Epoch: 15201, Train Acc: 0.7403, Test Acc: 0.7433\n",
      "Epoch: 15251, Train Acc: 0.7541, Test Acc: 0.7540\n",
      "Epoch: 15301, Train Acc: 0.7601, Test Acc: 0.7604\n",
      "Epoch: 15351, Train Acc: 0.7632, Test Acc: 0.7604\n",
      "Epoch: 15401, Train Acc: 0.7613, Test Acc: 0.7623\n",
      "Epoch: 15451, Train Acc: 0.7628, Test Acc: 0.7687\n",
      "Epoch: 15501, Train Acc: 0.7596, Test Acc: 0.7637\n",
      "Epoch: 15551, Train Acc: 0.7670, Test Acc: 0.7716\n",
      "Epoch: 15601, Train Acc: 0.7705, Test Acc: 0.7724\n",
      "Epoch: 15651, Train Acc: 0.7686, Test Acc: 0.7723\n",
      "Epoch: 15701, Train Acc: 0.7677, Test Acc: 0.7686\n",
      "Epoch: 15751, Train Acc: 0.7516, Test Acc: 0.7520\n",
      "Epoch: 15801, Train Acc: 0.7695, Test Acc: 0.7746\n",
      "Epoch: 15851, Train Acc: 0.7663, Test Acc: 0.7701\n",
      "Epoch: 15901, Train Acc: 0.7719, Test Acc: 0.7743\n",
      "Epoch: 15951, Train Acc: 0.7664, Test Acc: 0.7754\n",
      "Epoch: 16001, Train Acc: 0.7734, Test Acc: 0.7801\n",
      "Epoch: 16051, Train Acc: 0.7668, Test Acc: 0.7692\n",
      "Epoch: 16101, Train Acc: 0.7691, Test Acc: 0.7772\n",
      "Epoch: 16151, Train Acc: 0.7543, Test Acc: 0.7574\n",
      "Epoch: 16201, Train Acc: 0.7526, Test Acc: 0.7554\n",
      "Epoch: 16251, Train Acc: 0.7514, Test Acc: 0.7585\n",
      "Epoch: 16301, Train Acc: 0.7325, Test Acc: 0.7356\n",
      "Epoch: 16351, Train Acc: 0.7399, Test Acc: 0.7441\n",
      "Epoch: 16401, Train Acc: 0.7451, Test Acc: 0.7452\n",
      "Epoch: 16451, Train Acc: 0.7391, Test Acc: 0.7447\n",
      "Epoch: 16501, Train Acc: 0.7430, Test Acc: 0.7484\n",
      "Epoch: 16551, Train Acc: 0.7272, Test Acc: 0.7281\n",
      "Epoch: 16601, Train Acc: 0.7316, Test Acc: 0.7337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16651, Train Acc: 0.7345, Test Acc: 0.7284\n",
      "Epoch: 16701, Train Acc: 0.7373, Test Acc: 0.7364\n",
      "Epoch: 16751, Train Acc: 0.7460, Test Acc: 0.7391\n",
      "Epoch: 16801, Train Acc: 0.7359, Test Acc: 0.7297\n",
      "Epoch: 16851, Train Acc: 0.7395, Test Acc: 0.7357\n",
      "Epoch: 16901, Train Acc: 0.7556, Test Acc: 0.7500\n",
      "Epoch: 16951, Train Acc: 0.7572, Test Acc: 0.7486\n",
      "Epoch: 17001, Train Acc: 0.7614, Test Acc: 0.7566\n",
      "Epoch: 17051, Train Acc: 0.7558, Test Acc: 0.7563\n",
      "Epoch: 17101, Train Acc: 0.7705, Test Acc: 0.7725\n",
      "Epoch: 17151, Train Acc: 0.7712, Test Acc: 0.7767\n",
      "Epoch: 17201, Train Acc: 0.7606, Test Acc: 0.7593\n",
      "Epoch: 17251, Train Acc: 0.7675, Test Acc: 0.7722\n",
      "Epoch: 17301, Train Acc: 0.7670, Test Acc: 0.7679\n",
      "Epoch: 17351, Train Acc: 0.7609, Test Acc: 0.7630\n",
      "Epoch: 17401, Train Acc: 0.7621, Test Acc: 0.7637\n",
      "Epoch: 17451, Train Acc: 0.7591, Test Acc: 0.7633\n",
      "Epoch: 17501, Train Acc: 0.7437, Test Acc: 0.7394\n",
      "Epoch: 17551, Train Acc: 0.7508, Test Acc: 0.7543\n",
      "Epoch: 17601, Train Acc: 0.7582, Test Acc: 0.7604\n",
      "Epoch: 17651, Train Acc: 0.7540, Test Acc: 0.7571\n",
      "Epoch: 17701, Train Acc: 0.7522, Test Acc: 0.7582\n",
      "Epoch: 17751, Train Acc: 0.7484, Test Acc: 0.7553\n",
      "Epoch: 17801, Train Acc: 0.7451, Test Acc: 0.7520\n",
      "Epoch: 17851, Train Acc: 0.7489, Test Acc: 0.7550\n",
      "Epoch: 17901, Train Acc: 0.7585, Test Acc: 0.7665\n",
      "Epoch: 17951, Train Acc: 0.7501, Test Acc: 0.7561\n",
      "Epoch: 18001, Train Acc: 0.7302, Test Acc: 0.7394\n",
      "Epoch: 18051, Train Acc: 0.7352, Test Acc: 0.7410\n",
      "Epoch: 18101, Train Acc: 0.7300, Test Acc: 0.7361\n",
      "Epoch: 18151, Train Acc: 0.7360, Test Acc: 0.7398\n",
      "Epoch: 18201, Train Acc: 0.7389, Test Acc: 0.7432\n",
      "Epoch: 18251, Train Acc: 0.7197, Test Acc: 0.7199\n",
      "Epoch: 18301, Train Acc: 0.7421, Test Acc: 0.7401\n",
      "Epoch: 18351, Train Acc: 0.7413, Test Acc: 0.7470\n",
      "Epoch: 18401, Train Acc: 0.7317, Test Acc: 0.7372\n",
      "Epoch: 18451, Train Acc: 0.7394, Test Acc: 0.7438\n",
      "Epoch: 18501, Train Acc: 0.7475, Test Acc: 0.7496\n",
      "Epoch: 18551, Train Acc: 0.7432, Test Acc: 0.7455\n",
      "Epoch: 18601, Train Acc: 0.7293, Test Acc: 0.7337\n",
      "Epoch: 18651, Train Acc: 0.7342, Test Acc: 0.7375\n",
      "Epoch: 18701, Train Acc: 0.7190, Test Acc: 0.7266\n",
      "Epoch: 18751, Train Acc: 0.7330, Test Acc: 0.7352\n",
      "Epoch: 18801, Train Acc: 0.7360, Test Acc: 0.7344\n",
      "Epoch: 18851, Train Acc: 0.7402, Test Acc: 0.7432\n",
      "Epoch: 18901, Train Acc: 0.7357, Test Acc: 0.7380\n",
      "Epoch: 18951, Train Acc: 0.7411, Test Acc: 0.7363\n",
      "Epoch: 19001, Train Acc: 0.7368, Test Acc: 0.7297\n",
      "Epoch: 19051, Train Acc: 0.7401, Test Acc: 0.7400\n",
      "Epoch: 19101, Train Acc: 0.7397, Test Acc: 0.7374\n",
      "Epoch: 19151, Train Acc: 0.7423, Test Acc: 0.7472\n",
      "Epoch: 19201, Train Acc: 0.7271, Test Acc: 0.7289\n",
      "Epoch: 19251, Train Acc: 0.7339, Test Acc: 0.7427\n",
      "Epoch: 19301, Train Acc: 0.7403, Test Acc: 0.7492\n",
      "Epoch: 19351, Train Acc: 0.7304, Test Acc: 0.7388\n",
      "Epoch: 19401, Train Acc: 0.7385, Test Acc: 0.7463\n",
      "Epoch: 19451, Train Acc: 0.7425, Test Acc: 0.7538\n",
      "Epoch: 19501, Train Acc: 0.7373, Test Acc: 0.7457\n",
      "Epoch: 19551, Train Acc: 0.7480, Test Acc: 0.7562\n",
      "Epoch: 19601, Train Acc: 0.7357, Test Acc: 0.7361\n",
      "Epoch: 19651, Train Acc: 0.7124, Test Acc: 0.7178\n",
      "Epoch: 19701, Train Acc: 0.7295, Test Acc: 0.7362\n",
      "Epoch: 19751, Train Acc: 0.7254, Test Acc: 0.7307\n",
      "Epoch: 19801, Train Acc: 0.7196, Test Acc: 0.7266\n",
      "Epoch: 19851, Train Acc: 0.7293, Test Acc: 0.7394\n",
      "Epoch: 19901, Train Acc: 0.7248, Test Acc: 0.7310\n",
      "Epoch: 19951, Train Acc: 0.7284, Test Acc: 0.7351\n",
      "Epoch: 20001, Train Acc: 0.7218, Test Acc: 0.7316\n",
      "Epoch: 20051, Train Acc: 0.7340, Test Acc: 0.7467\n",
      "Epoch: 20101, Train Acc: 0.7300, Test Acc: 0.7425\n",
      "Epoch: 20151, Train Acc: 0.7239, Test Acc: 0.7374\n",
      "Epoch: 20201, Train Acc: 0.7265, Test Acc: 0.7359\n",
      "Epoch: 20251, Train Acc: 0.7268, Test Acc: 0.7361\n",
      "Epoch: 20301, Train Acc: 0.7137, Test Acc: 0.7133\n",
      "Epoch: 20351, Train Acc: 0.7335, Test Acc: 0.7420\n",
      "Epoch: 20401, Train Acc: 0.7480, Test Acc: 0.7544\n",
      "Epoch: 20451, Train Acc: 0.7305, Test Acc: 0.7449\n",
      "Epoch: 20501, Train Acc: 0.7308, Test Acc: 0.7451\n",
      "Epoch: 20551, Train Acc: 0.7278, Test Acc: 0.7386\n",
      "Epoch: 20601, Train Acc: 0.7339, Test Acc: 0.7507\n",
      "Epoch: 20651, Train Acc: 0.7387, Test Acc: 0.7502\n",
      "Epoch: 20701, Train Acc: 0.7113, Test Acc: 0.7216\n",
      "Epoch: 20751, Train Acc: 0.7282, Test Acc: 0.7382\n",
      "Epoch: 20801, Train Acc: 0.7181, Test Acc: 0.7288\n",
      "Epoch: 20851, Train Acc: 0.7175, Test Acc: 0.7296\n",
      "Epoch: 20901, Train Acc: 0.7192, Test Acc: 0.7318\n",
      "Epoch: 20951, Train Acc: 0.7229, Test Acc: 0.7308\n",
      "Epoch: 21001, Train Acc: 0.7255, Test Acc: 0.7299\n",
      "Epoch: 21051, Train Acc: 0.7325, Test Acc: 0.7351\n",
      "Epoch: 21101, Train Acc: 0.7288, Test Acc: 0.7353\n",
      "Epoch: 21151, Train Acc: 0.7270, Test Acc: 0.7342\n",
      "Epoch: 21201, Train Acc: 0.7354, Test Acc: 0.7456\n",
      "Epoch: 21251, Train Acc: 0.7332, Test Acc: 0.7396\n",
      "Epoch: 21301, Train Acc: 0.7304, Test Acc: 0.7356\n",
      "Epoch: 21351, Train Acc: 0.7322, Test Acc: 0.7375\n",
      "Epoch: 21401, Train Acc: 0.7402, Test Acc: 0.7503\n",
      "Epoch: 21451, Train Acc: 0.7440, Test Acc: 0.7578\n",
      "Epoch: 21501, Train Acc: 0.7386, Test Acc: 0.7523\n",
      "Epoch: 21551, Train Acc: 0.7273, Test Acc: 0.7372\n",
      "Epoch: 21601, Train Acc: 0.7347, Test Acc: 0.7425\n",
      "Epoch: 21651, Train Acc: 0.7314, Test Acc: 0.7392\n",
      "Epoch: 21701, Train Acc: 0.7359, Test Acc: 0.7465\n",
      "Epoch: 21751, Train Acc: 0.7362, Test Acc: 0.7414\n",
      "Epoch: 21801, Train Acc: 0.7342, Test Acc: 0.7423\n",
      "Epoch: 21851, Train Acc: 0.7321, Test Acc: 0.7417\n",
      "Epoch: 21901, Train Acc: 0.7160, Test Acc: 0.7246\n",
      "Epoch: 21951, Train Acc: 0.7238, Test Acc: 0.7284\n",
      "Epoch: 22001, Train Acc: 0.7331, Test Acc: 0.7426\n",
      "Epoch: 22051, Train Acc: 0.7181, Test Acc: 0.7252\n",
      "Epoch: 22101, Train Acc: 0.7292, Test Acc: 0.7318\n",
      "Epoch: 22151, Train Acc: 0.7528, Test Acc: 0.7590\n",
      "Epoch: 22201, Train Acc: 0.7487, Test Acc: 0.7533\n",
      "Epoch: 22251, Train Acc: 0.7528, Test Acc: 0.7624\n",
      "Epoch: 22301, Train Acc: 0.7558, Test Acc: 0.7698\n",
      "Epoch: 22351, Train Acc: 0.7367, Test Acc: 0.7535\n",
      "Epoch: 22401, Train Acc: 0.7435, Test Acc: 0.7556\n",
      "Epoch: 22451, Train Acc: 0.7301, Test Acc: 0.7468\n",
      "Epoch: 22501, Train Acc: 0.7351, Test Acc: 0.7417\n",
      "Epoch: 22551, Train Acc: 0.7500, Test Acc: 0.7585\n",
      "Epoch: 22601, Train Acc: 0.7296, Test Acc: 0.7431\n",
      "Epoch: 22651, Train Acc: 0.7320, Test Acc: 0.7478\n",
      "Epoch: 22701, Train Acc: 0.7421, Test Acc: 0.7546\n",
      "Epoch: 22751, Train Acc: 0.7409, Test Acc: 0.7518\n",
      "Epoch: 22801, Train Acc: 0.7340, Test Acc: 0.7412\n",
      "Epoch: 22851, Train Acc: 0.7267, Test Acc: 0.7335\n",
      "Epoch: 22901, Train Acc: 0.7365, Test Acc: 0.7388\n",
      "Epoch: 22951, Train Acc: 0.7413, Test Acc: 0.7464\n",
      "Epoch: 23001, Train Acc: 0.7419, Test Acc: 0.7524\n",
      "Epoch: 23051, Train Acc: 0.7437, Test Acc: 0.7488\n",
      "Epoch: 23101, Train Acc: 0.7207, Test Acc: 0.7188\n",
      "Epoch: 23151, Train Acc: 0.7437, Test Acc: 0.7482\n",
      "Epoch: 23201, Train Acc: 0.7291, Test Acc: 0.7323\n",
      "Epoch: 23251, Train Acc: 0.7387, Test Acc: 0.7461\n",
      "Epoch: 23301, Train Acc: 0.7313, Test Acc: 0.7351\n",
      "Epoch: 23351, Train Acc: 0.7374, Test Acc: 0.7396\n",
      "Epoch: 23401, Train Acc: 0.7197, Test Acc: 0.7267\n",
      "Epoch: 23451, Train Acc: 0.7243, Test Acc: 0.7295\n",
      "Epoch: 23501, Train Acc: 0.7077, Test Acc: 0.7172\n",
      "Epoch: 23551, Train Acc: 0.7291, Test Acc: 0.7313\n",
      "Epoch: 23601, Train Acc: 0.7104, Test Acc: 0.7211\n",
      "Epoch: 23651, Train Acc: 0.7049, Test Acc: 0.7116\n",
      "Epoch: 23701, Train Acc: 0.6988, Test Acc: 0.7046\n",
      "Epoch: 23751, Train Acc: 0.7024, Test Acc: 0.7067\n",
      "Epoch: 23801, Train Acc: 0.7018, Test Acc: 0.7077\n",
      "Epoch: 23851, Train Acc: 0.6898, Test Acc: 0.7006\n",
      "Epoch: 23901, Train Acc: 0.7295, Test Acc: 0.7390\n",
      "Epoch: 23951, Train Acc: 0.7156, Test Acc: 0.7190\n",
      "Epoch: 24001, Train Acc: 0.7243, Test Acc: 0.7266\n",
      "Epoch: 24051, Train Acc: 0.6976, Test Acc: 0.6965\n",
      "Epoch: 24101, Train Acc: 0.7184, Test Acc: 0.7183\n",
      "Epoch: 24151, Train Acc: 0.7038, Test Acc: 0.7058\n",
      "Epoch: 24201, Train Acc: 0.6953, Test Acc: 0.6983\n",
      "Epoch: 24251, Train Acc: 0.7059, Test Acc: 0.7024\n",
      "Epoch: 24301, Train Acc: 0.6935, Test Acc: 0.6908\n",
      "Epoch: 24351, Train Acc: 0.7051, Test Acc: 0.6997\n",
      "Epoch: 24401, Train Acc: 0.7110, Test Acc: 0.7037\n",
      "Epoch: 24451, Train Acc: 0.7127, Test Acc: 0.7087\n",
      "Epoch: 24501, Train Acc: 0.6969, Test Acc: 0.6927\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 45.8 MiB for an array with shape (60000, 100) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_5760/4021528617.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mtrain_acc_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_5760/274205304.py\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(self, x, true_y)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mpred_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mpred_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_5760/274205304.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_5760/1282022764.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 45.8 MiB for an array with shape (60000, 100) and data type float64"
     ]
    }
   ],
   "source": [
    "#Hyper Parameters\n",
    "epochs = 30000\n",
    "learning_rate = 1e-2\n",
    "batch_size = 10\n",
    "train_size = X_train.shape[0]\n",
    "#모델 생성 및 학습\n",
    "model = MyModel(28 * 28, [100, 64, 32], 10, activation='sigmoid')\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "for epoch in range(epochs):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = X_train[batch_mask]\n",
    "    y_batch = y_train[batch_mask]\n",
    "    \n",
    "    grad = model.gradient(x_batch, y_batch)\n",
    "    \n",
    "    for key in model.params.keys():\n",
    "        model.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    loss = model.loss(x_batch, y_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        train_acc = model.accuracy(X_train, y_train)\n",
    "        test_acc = model.accuracy(X_test, y_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"Epoch: {}, Train Acc: {:.4f}, Test Acc: {:.4f}\".format(epoch + 1, train_acc, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc8fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "plt.plot(np.arange(epochs//50), train_acc_list, 'r--', label='train_acc')\n",
    "plt.plot(np.arange(epochs//50), test_acc_list, 'b--', label='test_acc')\n",
    "\n",
    "plt.title('Result')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=5)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(epochs), train_loss_list, 'green', label='train_loss')\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(loc=5)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311ed02d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
